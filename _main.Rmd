--- 
title: "A Minimal Book on R"
author: "Pascal Bessonneau"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg
description: 
  This is a minimal example of using the bookdown package to write a book.
  The HTML output format for this example is bookdown::gitbook,
  set in the _output.yml file.
link-citations: yes
github-repo: pbessonneau/Cours_R_2024
---

# Objectif    

Ce document constitue la trame du cours sur R pour les doctorants "orientation"
du CRTD du CNAM.

Il n'est pas exhaustif et se place plutôt en appui du cours de M. Kilani. Il est
construit sur les bases et sur les difficultés du langage.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->


# Architecture de R

```{r setup_architecture, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
library(readxl)
```

```{r,echo=FALSE}
parcours <- read_excel("data/fr-esr-parcoursup.xlsx")
```

R est à l'origine un logiciel de statistiques. Pour en faciliter l'usage il y
avait une interface très rugueuse qui était livré avec sous Windows.

Pour l'utiliser, en fait,  il fallait écrire le code dans un bloc-notes (le code
est du texte brut) et le coller dans la console de R.

Vous pouvez toujours voir ce que ça donne en lançant R et non pas RStudio
sur votre bureau. En prenant la mesure qu'il y a eu beaucoup de progrès de fait.

Maintenant il existe RStudio, racheté par Posit. En fait c'est éditeur de texte
grandement amélioré. 

Vous tapez le script dans la fenêtre en haut à gauche et vous l'exécutez en 
cliquant sur l'icone ou CTRL+ENTREE. Vous pouvez limiter ce que vous exécutez
en sélectionnant du texte dans l'éditeur, seul le texte sélectionné sera soumis.

En clair, comme RStudio est un éditeur amélioré :
- le code qui n'est pas soumis, R ne le reconnait pas. Si vous créez une variable
en ligne 4 mais que vous ne le soumettez pas, quand vous aurez besoin de la 
variable en ligne 30, elle n'existera pas.
- l'éditeur de texte peut contenir autre chose que du texte simple. Par exemple
du RMarkdown comme c'est le cas pour ce document. C'est un langage qui produit
de l'HTML c'est-à-dire des pages web. Le Markdown est très simple, le langage
tient sur une feuille : [ici](https://www.markdownguide.org/cheat-sheet/).
- ou du LaTeX avec le mode knitr
- On peut des graphiques R dans la fenêtre RStudio (en bas à droite)
- RStudio peut servir pour la gestion de paquets
- ...

RStudio fait donc beaucoup de choses. 

A noter que Jamovi et JASP utilisent aussi R sauf que pour eux ce n'est presque 
plus visible. A part dans les extensions et/ou les modules. Il y a des modules 
Jamovi pour écrire du code R ou pour faire des modèles structuraux directement 
en R dans Jamovi.

Vous allez avoir une démonstration enregistré pour l'utilisation de RStudio.

Les autres choses à rappeler, c'est que R est un langage cassee dépendant :
- les noms de fonctions de R sont à écrire en **minuscules**
- un objet n'est pas le même si une ou plusieurs lettres sont en majuscule au lieu
d'être en minuscule.

```{r}
aAa <- 2
AAa <- 4
```

donc 
```{r}
AAa
```

et
```{r}
aAa
```

Les commentaires dans R sont à noter avec des #. Tout ce qui suit le # est un 
commentaire.

Comme RStudio vous l'aurez remarqué vous aide en analysant et en colorant le 
code, n'utilisez pas un script R pour mettre des remarques (et non du code) en
dehors de commentaires. Sinon c'est la catastrophe...

**Utiliser toujours RStudio en mode Projet**

## Paquets

Les fonctionnalités de R sont finalement assez limitées. Il fait un certain 
nombre de statistiques et surtout fourni des outils mathématiques puissants
mais ça grande force est de proposer des paquets qui ajoute des fonctionnalités.

Ces paquets sont développés par des gens (qui font ça sur leur temps personnel
ou professionnel), des entreprises, des fondations, ...

La liste des paquets officiels est [là](https://cran.r-project.org/web/packages/available_packages_by_name.html)

Ils sont maintenant pléthoriques et je vous conseille de vous reportez [à cette page](https://cran.r-project.org/web/views/).

Elles répertorient les paquets utiles par domaine d'application. De plus les
paquets un peu douteux en qualité n'y figure pas. Donc c'est du solide.


Pour cela je vous recommande de l'utiliser pour se faire, suivez les instructions ci-dessous:
```{r,eval=FALSE}
install.packages("ctv")
```

Puis quand vous voulez installer une vue (SocialSciences par exemple) : 

```{r,eval=FALSE}
library(ctv)
install.views("SocialSciences")
```

On vient de voir comment appeler un paquet :
```{r}
library(tidyverse)
```


ou


```{r}
require(tidyverse)
```

Cela revient presque au même. Presque. Pour commencer vous pouvez utiliser 
__library__ en priorité.

Essayez d'installer un paquet :

```{r,eval=FALSE}
install.packages("readxl")
```

Maintenant vous pouvez lire les fichiers Excel. Vous n'avez besoin d'installer
le paquet qu'une fois mais vous devez le réclamer avec __library__ la première
fois que vous l'utilisez dans un script. La politique est de charger tous les 
paquets que vous utilisez **en tête du script**.

Maintenant on va faire des statistiques.








<!--chapter:end:00-Architecture.Rmd-->

# Le langage R 

## Introduction

Le but est d'aborder des notions et de voir quelques exemples.

R ne fonctionne pas comme JASP, Jamovi, SAS ou SPSS. Par exemple SPSS, vous ouvrez une 
source de données et vous voyez vos données sur un tableur.

Quand vous passez une commande sur SPSS, il n'y a pas d'ambiguité, le traitement
se fait sur le tableur actif.

Avec SAS, on ajoute une dose de complexité, car vous avez des bibliothèques
et des tables. 

Dans les deux cas, quand vous lancez une procédure statistique vous récupérez
les résultats dans une fenêtre dédié car il y a une séparation des données
et des résultats (dans la quasi-totalité des cas).

Avec R, c'est différent. R est un langage de programmation comme Python, Pascal,
Rust, etc.

La force de R et ce qui le rend compliqué est qu'il n'y a pas de séparation aussi
stricte entre données et résultats. 

Vous avez des objets en mémoire dans R et ces objets peuvent servir aussi bien 
de sources de données, d'arguments pour sélectionner une partie des résultats ou 
bien être des résultats d'une opérations statistiques.

## Un exemple de traitement de données

On va travailler sur une base de données qui sont les iris de Fisher. C'est
plus simple car c'est un jeu de données qui est en mémoire dans R, on verra 
comment charger une source de données plus tard.


```{r}
data(iris)
```

Vous pouvez cliquer sur **iris** qui est apparu dans la fenêtre en haut
à droite de RStudio. Elle ouvre un tableur assez frustre mais qui permet
de visualiser les données.

Mais c'est une très mauvaise habitude d'utiliser ce tableur pour visualiser
les données. 

Il vaut mieux taper : 

```{r}
str(iris)
```

**str** c'est pour __structure__. Enfin je crois. Elle vous décrit quelle est la
nature de l'objet et de quoi il est composé. Ca peut être rudemment complexe.

Mais là non. Il nous dit que c'est une **data.frame**. Le type **data.frame**
est ce qui se rapproche le plus d'un tableau de données comme dans SPSS ou Jamovi.

R nous dit que la data.frame a 150 observations et 5 variables. La structure est
tabulaire comme dans Jamovi ou JASP: on a 150 relevés de plante (individus) et
on a gardé 5 éléments caractérisant l'individu.

- Sepal.Length : **num** veut dire **numeric**, c'est une taille de Sépale.
- Sepal.Width : **num** veut dire **numeric**, c'est une taille de Sépale.
- ...
- Species : c'est l'espèce, qui peut prendre 3 valeurs. Dans un type appelé
**Factor**

On voit que R sépare bien chacune des variables. Pour schématiser dans notre cas
nous avons des individus en ligne et des observations en colonne. Comme Jamovi.

## Vecteurs

### Exemple de vecteurs

Là où ça devient différent c'est que la **data.frame** est en fait un aggrégat
d'élements plus simples.

Vous pouvez extraire par exemple la longueur des sépales pour tous les individus:
```{r}
iris[,"Sepal.Length"]
```

Vous regardez par colonne, vous obtenez les valeurs pour les 150 individus.

Si vous regardez la structure de ce que vous avez obtenu :
```{r}
str(iris[,"Sepal.Length"])
```

Vous voyez que ce qui s'affichait tout à l'heure sur la **data.frame**.

Vous pouvez calculer la moyenne des longueurs:
```{r}
mean(iris[,"Sepal.Length"])
```

Vous venez de faire une opération sur un vecteur. C'est un ensemble qui est typé
ici des numériques mais ça peut être du texte, des entiers, etc. respectivement 
**character**, **integer**, etc.

Vous pouvez extraire ce vecteur :
```{r}
longueur.sepale <- iris[,"Sepal.Length"]
```

Vous remarquez que R n'affiche pas le résultat de l'opération car on ne lui demande
pas de résultat. On affecte la partie à droite de "<-" à la partie gauche.

Si on fait:
```{r}
longueur.sepale
```
On retrouve bien nos longueurs.

On peut en calculer la moyenne :
```{r}
mean(longueur.sepale)
```

Qu'est ce qui se passe ? En fait on a indexé notre **data.frame**.

On a dit à R, renvoie nous la variable "Sepal.Length" et nous avons décidé de le
stocker dans une variable autre.

### Création de vecteurs

Pour créer un vecteur, il faut utiliser la fonction **c** pour __concatenate__.

Exemple :
```{r}
c("Sepal.Length","Petal.Length")
```

On peut l'affecter à une variable:
```{r}
longueurs <- c("Sepal.Length","Petal.Length")
```

C'est un vecteur :
```{r}
str(longueurs)
```


Maintenant on peut faire:

```{r}
iris[,longueurs]
```

On vient d'indexer iris avec un vecteur composé de deux noms qui sont les noms
des variables.

R lit la partie droite de la virgule et comprends que nous voulons les deux variables.
Quelle est la structure de ce que l'on récupère :

```{r}
str(iris[,longueurs])
```

C'est une **data.frame** les informations sur nos 150 individus pour les longueurs.

on peut faire:
```{r}
iris.longueurs <- iris[,longueurs]
str(iris.longueurs)
```

```{r}
iris.longueurs[,"Sepal.Length"]
```

```{r}
mean(iris.longueurs[,"Sepal.Length"])
```

### Les types de vecteurs

les vecteurs en résumé peuvent être :
- des numéros entiers, **int**
- des chaines de caractères, **chr**
- des logiques, **logi**
- des réels, **num**
- ...

On peut créer un vecteur d'entiers
```{r}
c(1,3)
```

Un vecteur de logique: (T pour vrai, F pour faux) 
```{r}
c(T,F,T,F,F)
```

Et là surprise : si on demande à R de nous retourner la première et la troisième
variable de iris 
```{r}
str(iris[,c(1,3)])
```

Plus compliqué. On sait qu'il y a 5 variables dans iris ? On est d'accord ?
Donc si on lui demande de nous renvoyer la variable quand c'est vrai et de ne pas
nous la renvoyer quand c'est faux ?

```{r}
str(iris[,c(T,F,T,F,F)])
```

En fait les **data.frame**s sont des agrégats de vecteurs que l'on peut indexer
avec des vecteurs.

Pourquoi on ne peut pas faire :
```{r,eval=F}
mean(iris.longueurs)
```

parce qu'on a deux variables ? R refuse de faire ce qui n'a pas de sens.

Après tout on voudrait faire la moyenne de sépale et de pétale. Déjà mais
ça pourrait être pire :

```{r,eval=FALSE}
mean(iris[,c("Sepal.Length","Species")])
```

C'est la catastrophe. Vous essayez de faire une moyenne sur une variable texte
et une variable continue. C'est faux.

Pour faire le résumer d'une variable texte:
```{r}
table(iris[,"Species"])
```

### Pour résumé

On a les **data.frame**, on a les **vector** de différents types. On sait qu'on
peut sélectionner les variables par l'intermédiaire de vecteurs.

## Sélection des individus

Intuitivement, comment sélectionner des individus ?

Ca marche comme pour les variables, on utilise des vecteurs ?

On veut les individus de 1 et 5.
```{r}
str(iris[c(1,5),])
```

Attention à la place de la virgule. Cette fois on sélectionne des lignes. A gauche
de la virgule pour des lignes et à droite pour les colonnes.

C'est tout bon. 

On a vu qu'il y avait trois espèces. Si on veut sélectionner ceux qui sont du type
__versicolor__ ?

On se rappele des vecteurs de logique: là où iris[,"Species"] vaudra __versicolor__
on sélectionne et là où ce n'est pas __versicolor__ on ne sélectionne pas.

On ne va pas le faire à la main. On ne fait rien à la main sous R.

```{r}
especes <- c("versicolor","truc","versicolor","setosa")
especes
```

```{r}
especes=="versicolor"
```

On l'adapte pour notre cas :
```{r}
iris[,"Species"]=="versicolor"
```

Donc on indexe les individus :
```{r}
versicolor <- iris[iris[,"Species"]=="versicolor",]
```

Faites un point pour voir si tout est conforme dans votre esprit sur la place
des accolades, etc. En fait c'est le __old-fashioned__ R.

En fait ça commence à devenir compliqué, alors des gens on fait des fonctions
qui génère des vecteurs... à partir de mots anglais.

On va créer ainsi de gauche à droite des sous espaces pour ne retenir que ce 
qui nous intéresse.

Exemple :
from iris, filter Species=="versicolor", 
```{r,message=F,warning=FALSE}
require(tidyverse)
```

```{r}
iris |> filter(Species=="setosa")
```

### Calcul de la moyenne et nouveaux générateurs

Pour la moyenne des longueurs de sépales ?

```{r}
iris |> summarise(moyenne=mean(Sepal.Length))  
```
Ce qui devient :
```{r}
iris |> filter(Species=="setosa") |> summarise(moyenne=mean(Sepal.Length))
```

Mais y'a des choses plus pratique.

```{r}
iris |> group_by(Species) |> summarise(moyenne=mean(Sepal.Length))

quantile(iris[,"Sepal.Length"])

iris |> group_by(Species) |> summarise(moy.Sepal.Length=mean(Sepal.Length),ec=sd(Sepal.Length),mediane=quantile(Sepal.Length,probs=0.5))

iris |> group_by(Species) |> summarise(moy.Sepal.Length=mean(Sepal.Length),ec=sd(Sepal.Length),mediane=quantile(Sepal.Length,probs=0.5),q90=quantile(Sepal.Length,probs=0.9))

```
Etc...

Ah au fait c'est quoi comme vient de retourner ?

```{r}
str(iris |> group_by(Species) |> summarise(sepal.length=mean(Sepal.Length),
                                       sepal.width=mean(Sepal.Width)))
```

Calculer la moyenne de toutes les colonnes sauf Species ? 

```{r}
iris |> group_by(Species) |> summarise(across(Sepal.Length:Petal.Width,mean))
```

  

<!--chapter:end:01-intro.Rmd-->


```{r packages_importation,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
```

# Importation de Données


## Parcours Sup.


Les données de ParcourSup viennent de là :
[Parcoursup 2023 - vœux de poursuite d'études et de réorientation dans l'enseignement supérieur et réponses des établissements](https://data.education.gouv.fr/explore/embed/dataset/fr-esr-parcoursup/table/?sort=tri)

sinon vous avez les métiers en tensions :
[Taux de pression et d'emploi pour les diplômes de la voie professionnelle](https://data.education.gouv.fr/explore/embed/dataset/fr-en-taux-de-pression-et-demploi/table/?disjunctive.diplome&disjunctive.type_dip_lib&disjunctive.filiere&disjunctive.specialite_lib)

En suivant les liens vous pouvez télécharger les fichiers Excel.

Déplacer le fichier Excel à la racine de votre projet. puis
```{r,eval=FALSE}
library(readxl)
```

```{r}
parcours <- read_excel("data/fr-esr-parcoursup.xlsx")

```

Je viens de créer une data.frame du nom de parcours avec le contenu du fichier
Excel.

Pour sélectionner les variables, utiliser le raccourci TAB. 



Pour charger un fichier SPSS, il faut aussi un paquet supplémentaire :
```{r,message=F,warning=F}
require(haven)
```

```{r}
patient <- read_sav("data/patient.sav")
```

C'est le même paquet pour les formats __SAS__ (__sas7bdat__) et __STATA__. On 
trouve le chargement des mêmes types de fichier dans le paquet __foreign__
mais attention ce sont pour les vieux formats de fichiers.

Par exemple pour SAS, il suffit de changer de fonction :
```{r,eval=FALSE}
patient <- read_sas("patient.sas7bdat")
```


Lors de l'import, de SAS, SPSS, il conserve le type de la variable. Quand on veux
importer un fichier Excel ou un fichier texte, cela est différent.

On va prendre l'exemple de fichier texte : l'importation se fait en fait en 
trois temps. 

```{r}
library(readr)
patient <- read_csv("data/patient.csv")
```
```{r}
table(patient$scoliose)
```


Dans un premier temps, la fonction __read_csv__ va parcourir les 1000 premières
lignes du fichier à la découverte de :
- du séparateur entre les champs
- du séparateur de décimales
- le type de chaque colonne.

Si par exemple il trouve que des chiffres dans une colonne, le type sera __dbl__.
Par contre s'il trouve un mélange de charactères et de chiffres, là rien ne va 
plus. Ca peut se produire par exemple lorsque vous avez des chiffres mélangés
à des valeurs manquantes qui sont représentés par des valeurs textes ou bien des
symboles textuels.

Les petites machines qui transforment les données en données typées sont des
parser. Elles sont d'ailleurs disponible à part :


```{r}
str(parse_double(c("1.56", "NA", "NA")))
```

NA est reconnu comme valeur manquante alors pas de souci, le 1.56 est reconnu.

et si on mettait 1,56 ?

```{r}
str(parse_double(c("1,56", "NA", "NA")))
```


pas terrible ce qui suit :


```{r}
str(parse_double(c("1.56", "NR", "NR")))
```


On rétablit la situation normale en mettant na = NR :


```{r}
str(parse_double(c("1.56", "NA", "NA"),na = "NR"))

```


Dans la jungle des parsers, on a les parsers : 
- parse_logical()
- parse_integer()
- parse_double()
- parse_character() 
- parse_number()
- parse_factor()
- parse_datetime() (may be the force with you)
- ...

Si vous avez bien suivi, la machine va lire les n premières lignes et à chaque
colonne essayer de deviner le type de variable et appeler le parser qui va
bien : ce sont les fonctions **guess_**. 


Ceux sont eux qui vont décider du type de variable que vous importez. Pour le 
faire vous même, il suffit de spécificier chaque à la main :


```{r}
read_csv("data/iris.csv", col_types = list(
  Sepal.Length = col_double(),
  Sepal.Width = col_double(),
  Petal.Length = col_double(),
  Petal.Width = col_double(),
  Species = col_factor(c("setosa", "versicolor", "virginica"))
))
```


Sur cette ligne, c'est un peu complexe et surtout cela fait appel à deux élements
que vous connaissez pas. Les **list**s et les **factor**s.

Un **factor** est un ensemble de valeurs fini : c'est comme ça que vous pouvez
coder un ensemble de valeurs que vous pouvez énumérer et que vous utiliseriez
par exemple dans une expérience. Par exemple, on peut avoir comme facteur :


- le nombre de cylindres de mtcars 4, 6 ou 8
- les médicaments dans une expérience en double aveugle: A, B, C
- ...

L'idée est qu'un facteur est à utiliser dans une ANOVA (un test de différences de
moyennes sur 1 à k groupes).


La liste est une **data.frame** libertaire : par libértaire j'entends qu'on peut
mettre n'importe objet et l'indexer (presque) comme une **data.frame**.


```{r}
a <- list(iris,c(1,2,3),LETTERS,mtcars[,c("cyl","mpg")])
str(a)
```

On voit que c'est un type **list**, les **data.frame**.










<!--chapter:end:02-Importation.Rmd-->


# Résumés rapides descriptives

```{r setup_gt_summary, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning = FALSE)
library(readxl)
library(readr)
patient <- read_csv("data/patient.csv")
```

## Les premières tables

```{r,message=FALSE}
library(gtsummary)
```



```{r}
tbl_summary(mtcars)
```



```{r}
tbl_summary(iris)
```

Plus fort, 


```{r}
tbl_summary(iris,by="Species")
```


On peut rajouter un test statistique:



```{r}
tbl_summary(iris,by="Species" ) %>% add_p() %>% add_overall()
```


```{r}
trial %>%
  tbl_cross(row = stage, col = trt, percent = "cell") %>%
  add_p() %>%
  bold_labels()
```


## Tableaux croisés

On peut faire des tris croisés et choisir le sens des pourcentages : par cellule,
 par ligne ou par colonne.


```{r}
patient %>%
  tbl_cross(row = Hopital, col = sexe, percent = "col") %>%
  add_p() %>%
  bold_labels()
```

## Themes

```{r}
theme_gtsummary_compact(set_theme = TRUE, font_size = NULL)

patient %>%
  tbl_cross(row = Hopital, col = sexe, percent = "col") %>%
  add_p() %>%
  bold_labels()

reset_gtsummary_theme()

```

## Exportation 

Pour les exporter avec le paquet __writexl__ :


```{r}
iris %>% tbl_summary(by=Species) %>%
  gtsummary::as_tibble() %>% 
  writexl::write_xlsx(., "example_gtsummary1.xlsx")
```

Sinon 

```{r}
iris %>% tbl_summary(by=Species) %>%
  gtsummary::as_gt() %>% 
  gt::gtsave(., "example_gtsummary3.rtf")
```


## Personnalisation des statistiques

Sans qu'il soit nécessaire de fonction, vous pouvez personnaliser les sortie.

Il suffit de changer la valeur de **statistic**.

Les mots-clefs sont, pour les variables quantitatives et qualtitatives :
- **{N_obs}** total number of observations

- **{N_miss}** number of missing observations

- **{N_nonmiss}** number of non-missing observations

- **{p_miss}** percentage of observations missing

- **{p_nonmiss}** percentage of observations not missing



Pour les variables quantitatives :
- **{mean}**

- **{median}** 

- **{sd}**

- les quantiles **{pDD}** avec DD un chiffre sur 100 comme **{p25}**

- **{min}**

- **{max}**


Pour les variables qualitatives :
- **{p}** le pourcentage

- **{n}**, nombre d'observations dans la cellule

- nombre total **{N}**

Il suffit alors de préciser les statistiques à afficher :

```{r}
iris %>% tbl_summary(statistic = list(
  all_continuous() ~ "{mean} ({sd}) {min} {max}",
  all_categorical() ~ "{n} / {N} ({p}%)")) %>%
  modify_footnote( all_stat_cols() ~ "Moyenne (EC) Min. Max.; Effectif cellule / Total (%)")

  
```

Vous pouvez également le faire sur plusieurs lignes en spécifiant que vous voulez
les statistiques sur plusieurs lignes avec un argument supplémentaire :

```{r}
iris %>%
  tbl_summary(
    type = all_continuous() ~ "continuous2",
    statistic = list(all_continuous() ~ c(
      "{N_nonmiss}",
      "{mean} ({sd})",
      "{median} ({p25}, {p75})",
      "{min}, {max}"
    ), all_categorical() ~ "{n} / {N} ({p}%)"))

```

Vous pouvez de même personnaliser en adaptant la langue :


```{r}
theme_gtsummary_language(language = "fr", decimal.mark = ",", big.mark = " ")
iris %>%
  tbl_summary(
    type = all_continuous() ~ "continuous2",
    statistic = list(all_continuous() ~ c(
      "{N_nonmiss}",
      "{mean} ({sd})",
      "{median} ({p25}, {p75})",
      "{min}, {max}"
    ), all_categorical() ~ "{n} / {N} ({p}%)"))
```

## Modèles


### Exemple de modèle de régression linéaire

On peut faire aussi des modèles avec gtsummary :


```{r}
tbl_merge(list(
  tbl_regression(
    lm(totalechelle~sexe+vitaux+dureeopmin,data=patient[patient$Hopital=="A",])
  ),
  tbl_regression(
    lm(totalechelle~sexe+vitaux+dureeopmin,data=patient[patient$Hopital=="B",])
  ))
)


```


Une liste des fonctionnalités est disponible là :
[Ici](https://www.danieldsjoberg.com/gtsummary/reference/theme_gtsummary.html#examples)





<!--chapter:end:03-gt_summary.Rmd-->


# Graphiques et ggplot



```{r setup_ggplot, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggrepel)
require(tidyverse)
patient <- read_csv("data/patient.csv")
```

Les graphiques sont une composante de R qui est en partie à l'origine de son 
succès car on peut de très beaux et ce depuis la création de R.



## Les graphiques de base



Certaines sont très simples d'autres un peu plus compliquées. Nous verrons dans
un premier temps les graphiques de base c'est-à-dire qui ne nécessitent pas de
charger un __package__.



### Pour les graphiques de chiffres



Les premières fonctions présentées sont les plus usuelles comme les histogrammes.

```{r poids1}
hist(patient$poids)
```

Ce n'est pas très esthétique. Il y a des arguments aux fonctions qui permettent
d'améliorer les choses. 

Déjà changer les noms des axes X et y, notamment se débarasser de **Frequency**
qui est un faux ami en français.

```{r poids2}
hist(patient$poids,xlab="Poids",ylab="Effectifs")
```
Ensuite le titre :

```{r poids3}
hist(patient$poids,xlab="Poids",ylab="Effectifs",main="Poids des patients")
```

Pour la couleur, c'est un peu plus compliqué. En effet il y a simple des couleurs
qui répondent à leurs mots en anglais, la liste est [là](https://www.datanovia.com/en/blog/awesome-list-of-657-r-color-names/).

Mais les couleurs correspondent au codage web des couleurs qui sont en fait des
hexadécimaux. Si vous voulez personnaliser plus les couleurs, je vous conseille
le paquet **RColorBrewer** qui possède de jolis (et intelligents) assortiments
de couleurs et [de la lecture](https://larmarange.github.io/analyse-R/couleurs.html)

```{r}
hist(patient$poids,xlab="Poids",ylab="Effectifs",main="Poids des patients",col="lightblue")
```
Ensuite il y a les boxplots ou boîtes à moustache pour les variables continues.

```{r poids4}
boxplot(patient$poids)
```

De même on arrange un peu :

```{r poids5}
boxplot(patient$poids,ylab="Poids",main="Poids des patients")

```
Pour les boxplots on peut faire un peu mieux, par exemple pour segmenter par type
de pathologies.

On passe la **data.frame** patient et on précise le nom de la variable qualitative
qui doit "séparer" les tracés.

```{r poids6}
boxplot(poids ~ CIM2, data = patient,ylab="Poids",main="Poids des patients en fonction du CIM2") 
```
Le premier argument doit vous paraître un peu abstrait. En fait c'est une formule
sous R. C'est l'équivalent de "patient=CIM2".

A gauche du ~ on place la variable à expliquer et à droite la ou les variables
explicatives. Ici on en a une de chaque côté.

Le graphique le plus simple serait le **scatterplot**. On aurait pu commencer
par lui :

Cette fois on a deux arguments qui sont la variable numérique des x en premier
et la variable numérique des y en second.

```{r poids7}
plot(patient$poids,patient$dureeopmin)
```


```{r poids8}
plot(patient$poids,patient$dureeopmin,xlab="Poids",ylab="Durée opération en minutes")
```
Qui aurait pu s'écrire :

```{r poids9}
plot(dureeopmin ~ poids,data=patient,xlab="Poids",ylab="Durée opération en minutes")
```
Si on veut tracer une ligne pour la régression linéaire, il faut faire appel
à la fonction **lm** qui calcule la régression et R se charge du reste.

```{r poids10}
coefficients <- lm(dureeopmin ~ poids,data=patient)
plot(patient$poids,patient$dureeopmin,xlab="Poids",ylab="Durée opération en minutes")
abline(coefficients)
```
On voit ici que j'ai appellé **abline** après le plot. En effet, il est nécessaire
de faire un **plot**, un **hist** ou une **boxplot** avant pour que R initialise
le graphique notamment le calcul des coordonnées maximales et minimales.

D'ailleurs on peut les spécifier nous mêmes :

```{r poids11}
coefficients <- lm(dureeopmin~poids,data=patient)
plot(patient$poids,patient$dureeopmin,xlab="Poids",ylab="Durée opération en minutes",
     xlim=c(0,150),ylim=c(0,600),type="n")
abline(coefficients)
text(patient$poids,patient$dureeopmin,patient$UID)
```

Pour sauvegarder un graphique, on doit le faire avant d'appeler la fonction 
__principale__ et refermer le fichier avec la commande __dev.off__:

```{r,include=FALSE}
png("figure-1.png")
coefficients <- lm(dureeopmin~poids,data=patient)
plot(patient$poids,patient$dureeopmin,xlab="Poids",ylab="Durée opération en minutes",
     xlim=c(0,150),ylim=c(0,600))
abline(coefficients)
dev.off()
```

La dernière fonction à connaître pour les graphiques de base est le **barplot**.

Il s'agit de représenter des tableaux de contingence, le plus simple étant à une
dimension :

```{r sexe1}
tableau <- table(patient$sexe)
barplot(tableau, main = "sexe", ylab = "Effectifs")
```
On peut lui passer un argument à deux dimensions mais la table devient tout de 
suite difficile à lire.

```{r sexe2}
tableau <- table(patient$CIM2,patient$sexe)
barplot(tableau, main = "CIM2", ylab = "Effectifs")
```




## le tidyverse et ggplot



Vous pourrez comme précédemment entendre parler des graphiques de base de même
que des graphiques __lattice__ mais le choucou du **tidyverse** c'est **ggplot2**.

C'est un éco-système de **packages** qui permet de faire la plupart des graphiques
plus simplement et qui est basé sur le paquet **gplot2**.

Un livre gratuit lui est consacré [là](https://ggplot2-book.org/) et une page
en français [là](https://larmarange.github.io/analyse-R/graphiques-bivaries-ggplot2.html)

```{r,include=FALSE}
library(ggplot2)
```

On va reprendre notre grammaire. Il faut saisir que **ggplot2** fonctionne par 
couche. Sur une base, vous additionner des couches qui apporte la personnalisation
des graphiques.



### La base


Au tout départ, il faut lui passer une **data.frame**, c'est le passage obligé.

```{r ggplot1}
ggplot(patient)
```
Ensuite on précise les variables de travail. Pour l'histogramme, on en a qu'une :

```{r ggplot2}
ggplot(patient,aes(poids))
```

Vous pouvez constater, que le logiciel a calculé et positionner les légendes
pour créer un graphique avec poids comme variable des abscisses (horizontal).

On personnalise en demandant un graphique de type histogramme. En additionnant
littéralement:

```{r ggplot3}
ggplot(patient,aes(poids))+geom_histogram()
```

Pour modifier les limtes du graphiques, on rajoute :

```{r ggplot4}
ggplot(patient,aes(poids))+geom_histogram()+
  scale_x_continuous(limits = c(0,150)) +
  scale_y_continuous(limits = c(0,20))
```


Si on veut modifier le nombre de barres verticales (la précision de l'histogramme), 
on précise l'option dans la couche de l'histogramme :


```{r ggplot5}
ggplot(patient,aes(poids))+geom_histogram(bins=10)+
  scale_x_continuous(limits = c(0,150))
```
Pour les titres, c'est pareil, on ajoute des couches :

```{r ggplot6}
ggplot(patient,aes(poids))+geom_histogram()+
  scale_x_continuous(limits = c(0,150)) + 
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Effectifs")
```
On peut ajouter des propriétés esthétiques comme la couleur, par exemple :

```{r ggplot7}
ggplot(patient,aes(poids))+geom_histogram(fill ="lightblue", colour = "black")+
  scale_x_continuous(limits = c(0,150)) + 
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Effectifs")
```

Là où **ggplot2** sort du lot, c'est sa capacité à segmenter et à représenter
avec [une bonne grammaire graphique](https://link.springer.com/book/10.1007/0-387-28695-0)

```{r ggplot8}
ggplot(patient,aes(poids,fill=sexe))+geom_histogram(color="black")+
  scale_x_continuous(limits = c(0,150)) + 
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Effectifs")
```

On a l'ajout de couleurs ou alors deux graphiques avec des unités bien choisies:


```{r ggplot9}
ggplot(patient,aes(poids,fill=sexe))+geom_histogram(color="black")+
  scale_x_continuous(limits = c(0,150)) + 
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Effectifs") +
  facet_grid(sexe ~ .)
```


On a de nouveau une formule. Cette fois, c'est à gauche du ~ les lignes et
à droite les colonnes :



```{r ggplot10}
ggplot(patient,aes(poids))+geom_histogram(color="black")+
  scale_x_continuous(limits = c(0,150)) + 
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Effectifs") +
  facet_grid(sexe ~ Hopital)
```

On peut vouloir calculer la **densité** et non les effectifs dans ce cas :

```{r ggplot11}
ggplot(patient,aes(poids))+geom_histogram(aes(y = ..density..),color="black")+
  scale_x_continuous(limits = c(0,150)) + 
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Densité") +
  facet_grid(sexe ~ Hopital)

```




### Les autres graphiques



Le boxplot :

```{r ggplot12}
ggplot(patient,aes(x=poids,fill=sexe))+geom_boxplot()+
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Densité") +
  facet_grid(Hopital ~ .)
```



```{r ggplot13}
ggplot(patient,aes(x=sexe,y=poids))+geom_boxplot()+
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Densité") +
  facet_grid(Hopital ~ .)
```


```{r ggplot14}
ggplot(patient,aes(poids))+geom_boxplot()+
  ggtitle("Poids des patients") + 
  xlab("Poids") + 
  ylab("Densité") +
  facet_grid(sexe ~ Hopital)
```

D'où des graphiques en **scatterplot** comme :

```{r ggplot15}
ggplot(patient,aes(x=poids,y=dureeopmin))+geom_point(aes(col=sexe))+
  ggtitle("Caractéristiques des patients") + 
  xlab("Poids") + 
  ylab("Durée de l'opération en minutes") 
```

ou en rajoutant plein de trucs :

```{r ggplot16}
ggplot(patient,aes(x=poids,y=dureeopmin))+geom_point(aes(col=sexe))+
  ggtitle("Caractéristiques des patients") + 
  xlab("Poids") + 
  ylab("Durée de l'opération en minutes") +
  facet_grid(CIM2 ~ Hopital)
```

Si on veut ajouter une variable de gravité inversée par rapport à la variable
CIM2, avec 1 l'opération la plus grave et 4 l'opération bénigne:

```{r}
patient$Gravité <- LETTERS[5 - patient$CIM2]
ggplot(patient,aes(x=poids,y=dureeopmin))+geom_point(aes(col=sexe))+
  ggtitle("Caractéristiques des patients") + 
  xlab("Poids") + 
  ylab("Durée de l'opération en minutes") +
  facet_grid(Gravité ~ Hopital)
```



Pour rajouter une droite de régression :

```{r ggplot17a}
ggplot(patient,aes(x=poids,y=dureeopmin))+geom_point(aes(col=sexe))+
  geom_smooth(method="lm") +
  ggtitle("Caractéristiques des patients") + 
  xlab("Poids") + 
  ylab("Durée de l'opération en minutes") +
  facet_grid(CIM2 ~ Hopital)
```
Des courbes de tendances :

```{r ggplot18}
ggplot(patient,aes(x=poids,y=dureeopmin))+geom_point(aes(col=sexe))+
  geom_smooth() +
  ggtitle("Caractéristiques des patients") + 
  xlab("Poids") + 
  ylab("Durée de l'opération en minutes") +
  facet_grid(CIM2 ~ Hopital)
```

Sans l'intervalle de confiance :

```{r ggplot19}
ggplot(patient,aes(x=vitaux,y=totalechelle))+geom_point(aes(col=sexe))+
  geom_smooth(se=FALSE) +
  ggtitle("Caractéristiques des patients") + 
  xlab("Poids") + 
  ylab("Durée de l'opération en minutes") +
  facet_grid(CIM2 ~ Hopital)
```

Avec l'intervalle de confiance et la droite de régression :

```{r ggplot20}
ggplot(patient,aes(x=dureeopmin,y=totalechelle))+geom_point(aes(col=sexe))+
  geom_smooth(method="lm",se=FALSE) +
  ggtitle("Total des échelles de douleur et durée opération") + 
  xlab("Durée de l'opération en minutes") + 
  ylab("Total des échelles de douleur") +
  facet_grid(CIM2 ~ Hopital)
```

Pour ajouter des étiquettes, il existe la librairie **ggrepel** qui permet 
de faire en sorte que la superposition des étiquettes soit minimale :

```{r ggplot21,message=F,warning=FALSE}
ggplot(patient,aes(x=dureeopmin,y=totalechelle,label=UID))+geom_point(aes(col=sexe))+
  geom_smooth(method="lm",se=FALSE) +
  geom_text_repel() +
  ggtitle("Total des échelles de douleur et durée opération") + 
  xlab("Durée de l'opération en minutes") + 
  ylab("Total des échelles de douleur") 
```

Evidemment toutes les étiquettes ne sont pas dessinés car il y a trop d'individus
mais cela permet de repérer les individus atypiques.


### Tableaux de contingences


Pour les tableaux de fréquences, on peut faire très simple :

```{r ggplot17b}
ggplot(patient,aes(sexe))+geom_bar()
```

```{r ggplot18b}
ggplot(patient,aes(sexe))+geom_bar()+
  facet_grid(.~Hopital)
```
Là où **ggplot2** commence à devenir compliqué, c'est que **geom_bar** ne va pas
marcher car il faut lui fournir la **data.frame** avec les statistiques **en ligne**.

Soit :

```{r,echo=FALSE}
require(reshape2)
tableau <- table(patient$sexe,patient$CIM2)
long <- melt(tableau,varnames = c("sexe","CIM2"),value.name = "effectif")
long
```

Pour faire ce tableau, il faut faire appel au **package** **reshape2**.

```{r}
require(reshape2)
tableau <- table(patient$sexe,patient$CIM2)
tableau
```

De ce tableau on passe au long en une commande :

```{r}
long <- melt(tableau,varnames = c("sexe","CIM2"),value.name = "value")
```

Il faut spécifier le nom à donner aux deux variables et spécifier le résultat
du croisement des deux variables qui est le nombre d'observations c'est-à-dire
le contenu de chaque cellule de __tableau__.

```{r ggplot30}
ggplot(long,aes(x=sexe,y=value,fill=CIM2))+geom_bar(position = "stack",stat="identity")
```

Je dois faire de CIM2 une variable qualitative explicitement. En effet, CIM2 est numérique
(un entier de 1 à 4). Aussi quand je donne le CIM2 à l'argument **fill=** il ne sait pas
s'il s'agit de la couleur (qui peut être un code numérique aussi) ou d'une variable qualitative.

```{r ggplot31}
ggplot(long,aes(x=sexe,y=value,fill=factor(CIM2)))+geom_bar(position = "dodge",stat="identity")
```

D'où le graphique :

```{r ggplot32}
tableau <- table(patient$Hopital,patient$sexe,patient$CIM2)
long <- melt(tableau,varnames = c("Hopital","sexe","CIM2"),value.name = "effectif")
ggplot(long,aes(x=CIM2,y=effectif,fill=sexe))+
  geom_bar(position = "dodge",stat="identity")+
  facet_grid(Hopital ~ . )
```

Pour sauvegarder un graphique **ggplot2**, la syntaxe est différente et surtout 
on l'appelle une fois que le graphique est terminé, c'est-à-dire en dernier :

```{r,include=FALSE}
ggplot(long,aes(x=CIM2,y=effectif,fill=sexe))+geom_bar(position = "dodge",stat="identity")+theme_minimal()
ggsave("mon-graphique.png")

```


Et ainsi de suite...


### Les thèmes


Les graphiques de ggplot peuvent changer selon des thèmes qui définissent des styles
de graphique différents. Celui à retenir est minimal qui fait que le graphique
est épuré au maximum :

```{r}
tableau <- table(patient$Hopital,patient$sexe,patient$CIM2)
long <- melt(tableau,varnames = c("Hopital","sexe","CIM2"),value.name = "effectif")
ggplot(long,aes(x=CIM2,y=effectif,fill=sexe))+
  geom_bar(position = "dodge",stat="identity")+
  facet_grid(Hopital ~ . ) + theme_minimal()
```

Il y a 10 à 20 thèmes par défaut et il y a des variantes supplémentaires et de 
quoi personnaliser ses propres thèmes dans le package **ggthemes**.



## Liens



Il y a de nombreuses galleries sur le web avec toutes les possiblités offertes
par les graphiques de base comme les graphiques avec **ggplot2**.

- [r-graph-gallery](https://r-graph-gallery.com/)
- [r-chart](https://r-charts.com/ggplot2/)
- ...

On peut en parcourir ensemble...

```{r}
tableau <- dcast(patient, UID + sexe ~ Hopital, value.var = "nbechelle")
tableau$poids <- ifelse(!is.na(tableau$A),tableau$A,tableau$B)

ggplot(tableau, aes(x=nbechelle) ) +
  geom_density( aes(x = A, y = ..density..), fill="#69b3a2" ) +
  geom_label(aes(x=90, y=0.01, label="Hopital A"), color="#69b3a2") +
  geom_density( aes(x = B, y = -..density..), fill= "#404080") +
  geom_label(aes(x=90,y=-0.01, label="Hopital B"), color="#404080")

```


<!--chapter:end:04-graphiques-ggplot.Rmd-->


# Manipulation avancée (mettre en forme vos données)

```{r setup_manipulation, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggrepel)
library(gtsummary)
require(tidyverse)
patient <- read_csv("data/patient.csv")
```

Le but de cette partie qui ne sera pas très longue sur le papier mais beaucoup
plus à l'apprentissage est de vous montrer comment automatiser les choses.

Pour prendre un exemple qui nous est familier, transformer en facteur ou en
variable ordinale des items de plusieurs échelles. Sous SPSS ou sous R, c'est
pénible si vous n'utilisez pas les macros pour SPSS ou la programmation
sous R.

On peut automatiser beaucoup de choses sous R. Il y a des paquets sous
R qui permettent d'analyser des modèles structuraux ou faire des pages web 
interactives. Sans aller jusque là, on peut se rendre la vie plus facile.

## Transformation de plusieurs variables

On va charger le [fichier de données](https://personality-project.org/r/psych/HowTo/scoring.tutorial/small.msq.txt) en ligne : 

```{r,message=TRUE}
file.name <- "https://personality-project.org/r/psych/HowTo/scoring.tutorial/small.msq.txt"
msq <- read_table(file.name)
```

Oui au passage on peut lire des fichiers de données directement en ligne.

Dans ce cas, on a utilisé la commande **read_table** du **package readr**, car
le séparateur de champs est l'espace.

```{r}
str(msq)
```

On voit que les guillemets ont été importés et parasite la ligne des noms de colonnes.
Pour ça on utilise **gsub**, une fonction qui remplace les caractéères dans le premier
argument par les caractères dans le deuxième. Le troisième argument est **vecteur**
dans lequel on veut remplacer le texte. 

Ici on va remplacer un guillemet double, partout, par aucun caractère. Et on applique
ça aux noms de variables de msq, ce qui nous donne :


```{r}
colnames(msq) <- gsub('"','',colnames(msq),fixed=T)
msq
```

Les commentaires de read.table indique que les colonnes sont toutes des nombres
réels de double précision. C'est très bien pour les analyses psychométriques
primaires avec **psych** mais pas avec lavaan qui réclame des facteurs.

On va utiliser la machine à automatiser **mutate_at** qui permet d'appliquer une
transformation sur une série de variable.

Dans le premier argument, on mets **vars()** et à l'intérieur quelque chose pour 
définir une ou des variables comme avec un **select**. 

Le deuxième argument est la fonction à appliquer et après les arguments optionnels.

```{r}
msq_fact <- msq
msq_fact <- msq_fact %>% mutate(across(active:at.ease,~ factor(.x,ordered=T)))
```

Pour être vraiment propre, on spécifierait les niveaux :

```{r}
msq_fact <- msq_fact %>% mutate(across(active:at.ease, ~ factor(.x,levels=c(0,1,2,3),ordered=T)))
```


```{r}
str(msq_fact)
```
Il y a des variantes à **mutate_at** comme **mutate_if**.

Par exemple, pour centrer/réduire les variables numériques :
```{r}
iris <- iris %>% mutate(across(where(is.numeric),scale))
```

Si la variable est numérique alors R va centrer/réduire la variable. Donc pas 
de problème avec **Species** qui est un facteur :

```{r}
str(iris)
```


Soit :

```{r}
iris %>% tbl_summary(statistic = list(
  all_continuous() ~ "{mean} ({sd})"),type = c(Sepal.Length:Petal.Width) ~ "continuous")
```




## Opérateurs et case_when

On appelle opérateur des mots-clefs généralement symbolique comme les +,/,==, etc.

Par exemple de très utile, il y a l'opérateur **%in%**.

Il prends un vecteur à gauche et un vecteur à droite. 

Dans le cas simple, avec un élement dans un vecteur à gauche, il renvoie vrai si 
l'élement à gauche est présent dans le vecteur de droite :

```{r}
3 %in% 1:5
```


```{r}
-1 %in% 1:5
```

Quand il y a plusieurs élements à gauche, l'opérateur renvoie une réponse pour 
chaque élement à gauche :

```{r}
c(1,3) %in% 1:5
```


```{r}
c(-1,3) %in% 1:5
```

Si on veut transformer msq en items dichotomiques, c'est-à-dire coder 0 ou 1 en
0 et 2 et 3 en 1. Alors ça devient facile.

En fait il y a deux façons de l'écrire. la première est __old school__.

On utilise la fonction **ifelse** pour renvoyer 0 ou 1 selon la réponse :

Pour comprendre **ifelse** un exemple :
```{r}
ifelse(c(TRUE,FALSE,TRUE,FALSE,FALSE),1,0)
```


**ifelse** renvoie 1 quand c'est vrai et 0 quand c'est faux. Ce qui nous donne
associé à notre nouvel opérateur:

```{r}
active <- ifelse(msq$active %in% c(2,3),1,0)
table(active)
```

C'est un peu brutal car on ne précise pas explicitement ce que va prendre les 
valeurs 0 et 1.

En plus élégant, il y a une variante à privilégier avec le **tidyverse**:

```{r}
msq2 <- msq %>% mutate(active=case_when(
      active %in% c(0,1) ~ 0,
      active %in% c(2,3) ~ 1,
      .default = NA
))
table(msq2$active)
```

Mais là, on ne fait qu'un variable à la fois, il faudrait appliquer une fonction
pour avoir le résultat sur toutes les variables.

Une fonction se définit par un corps de fonction, des arguments et un nom.

```{r}
ma.fonction <- function(x) {
  return(x)
}
```

Ce qui donne :

```{r}
ma.fonction(1)
```
Ce qui est en dernière ligne ou bien (c'est mieux) ce qui est indiqué entre parenthèses
pour la fonction **return** est renvoyée.

Donc notre fonction devient :

```{r}
dichotomiser <- function(x) {
  resultat <- case_when(
      x %in% c(0,1) ~ 0,
      x %in% c(2,3) ~ 1,
      .default = NA
  )
  return(resultat)
}
```


```{r}
table(dichotomiser(msq$active))
```

Pour l'appliquer, il faut se rappeler de **mutate_at**: 

```{r}
msq2 <- msq %>% mutate(across(active:at.ease,dichotomiser))
```

Ce qui donne bien :

```{r}
tbl_summary(msq2)
```



## Réutilisation de statistiques

Contrairement aux autres logiciels, les résultats statistiques sont la plupart 
du temps réutilisable par l'utilisateur.

Par exemple, sous Jamovi, il faut créer des variables __à la main__ pour créer 
des variables avec les quantiles. 

Pour créer ces variables sous R, c'est beaucoup plus simple, il n'y a pas besoin
de faire de tests (if):

```{r}
quantile(iris$Sepal.Length)
```
La fonction **quantile** nous renvoie les quartiles sous la forme d'un vecteur qu'il
suffit de combiner avec une autre fonction **cut**. Cette dernière crée des
variables facteurs à partir d'une variable quantitative et de points de césure.

Les points de césure sont fournis par la fonction **quantile**, par conséquent :

```{r}
table(cut(iris$Sepal.Length, breaks=quantile(iris$Sepal.Length)))
```
Pour généraliser :

```{r}
quartiles <- function(x) {
  cut(x, breaks=quantile(x))
}
iris2 <- iris %>% mutate(across(where(is.numeric),quartiles))
```

```{r}
tbl_summary(iris2)
```




<!--chapter:end:05-automatisation.Rmd-->


```{r setup_patient, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

<!-- # Analyse de la table Patient -->

## Chargement


```{r packages}
require(tidyverse)
patient <- read_csv("data/patient.csv")
```

```{r}
str(patient)
```
Ouch... Remettre en factor, les variables qui doivent l'être. Lequelles ?

```{r}
patient$Hopital <- factor(patient$Hopital)
patient$sexe <- factor(patient$sexe)
patient$CIM2 <- factor(patient$CIM2)
patient$ACP <- factor(patient$ACP,levels=c(0,1),labels=c("Non","Oui"))

```

Scoliose ça sera plus propre avec les différents champs et "non" en l'absence 
de scoliose...

```{r,echo=T}
patient$scoliose[is.na(patient$scoliose)] <- "Non"
table(patient$scoliose)
```
Ca serait bien de faire __scoliose2__

```{r}
patient$scoliose2 <- factor(ifelse(patient$scoliose=="Non","Non","Oui"))
```

Et pareil avec les drépanocytose donc avec __drepano__ et __drepano2__:

```{r,eval=FALSE}
...
```


Calculer la variable __moyechelle__ qui fait la moyenne des échelles de douleur :

```{r}
patient$moyechelle <- patient$totalechelle / patient$nbechelle
```


```{r}
summary(patient$postopj-patient$nbttt)
```

Juste pour voir __case__ : faire des catégories quand nbttt < 0, entre 0 et 10
et est supérieur à 10

```{r}
patient <- patient %>% mutate(
  nbttopj = factor(case_when(
    postopj-nbttt > 0 ~ "Sup à 0",
    postopj-nbttt <= 0 & postopj-nbttt > -5 ~ "Entre 0 et -5",
    postopj-nbttt <= -5 ~ "Inf à -5",
    .default = NA
  )))
```

```{r}
table(patient$nbttopj)
```


<!--chapter:end:06-patient.Rmd-->


# Données des lycées pro.

```{r setup_emploi, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(gtsummary)
library(knitr)
library(ggrepel)
```

## Importation des données

On importe les données qui sont contenues dans un fichier Excel.

```{r,message=FALSE,warning=FALSE}
lycee <- read_excel("data/fr-en-taux-de-pression-et-demploi.xlsx")
```

```{r}
str(lycee)
```
On a 185 lignes et 18 colonnes. A aller vérifier dans le fichier Excel.

C'est bon.

On a les colonnes __Code diplome...12__ et __Code diplome...15__ qui ont eu
un problème car elle porte le même nom sous Excel ce qui n'est pas possible dans R.
R a donc ajouter le numéro de la colonne lors de l'importation.


On vérifie qu'on a bien une seule année de diplôme : 

```{r}
table(lycee$`Année diplôme`)
```
On a vu que dans le tableau Excel, on a autant de valeurs pour le **diplôme** et le
la **Spécialité libellé** que de lignes... De même pour les colonnes **MEFSTAT**
et **Code Diplôme**.

On voit que la variable __première année__ n'est pas très utile non plus.

On regarde de loin comment ça se comporte :

```{r,message=FALSE,warning=FALSE}
theme_gtsummary_compact(set_theme = TRUE, font_size = NULL)
lycee %>% select(-`Année diplôme`,-Diplôme,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`
                 ) %>% 
  tbl_summary()
reset_gtsummary_theme()
```

On voit que les libellés sont assez variés, un peu trop avec des libellés comme
__Mer__ qui n'ont que 3 diplômes comme __Relation client, etc.__.

On regarde les valeurs extrèmes et les quantiles pour les variables quantitatives.


```{r}
theme_gtsummary_compact(set_theme = TRUE, font_size = NULL)
lycee %>% select(-`Année diplôme`,-Diplôme,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`
                 ) %>% select(where(is.numeric)) %>%
  tbl_summary(statistic = all_continuous() ~ "{mean} ({sd}) {min}-{max}")
reset_gtsummary_theme()

```


On voit que le code type diplome est reconnu comme numérique alors que c'est un 
code, donc on corrige :

```{r}
lycee$`Code type diplôme` <- factor(lycee$`Code type diplôme`)
```

Il y a aussi baleineau sous gravillons, il y a des zéros dans les taux et les admis.
Donc des spécialités ne doivent pas être assuré cette année là :

```{r}
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% 
  filter(`Admis apprentissage 2019`==0 | `Admis voie scolaire 2019` == 0)
kable(nuls)
```
On n'en a 27 qui apparemment ont un nombre admis nul soit dans l'apprentissage soit 
dans la voie scolaire.

```{r}
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% 
  filter(`Admis apprentissage 2019`==0 & `Admis voie scolaire 2019` == 0)
nrow(nuls)
```
Et apparemment aucun n'a de nul en même temps. 

On vérifie de ce qu'ils ont fait quand **Capacités** est nulle (division par zéro).

```{r}
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% 
  filter(`Capacité`==0)
kable(nuls)
```

En fait ils ont pas fait n'importe quoi, le taux de pression est **NA**.

Par contre au fil de la vérification, on a vu qu'il y avait des taux d'emploi nuls:

```{r}
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% 
  filter(`Taux d'emploi`==0)
kable(nuls)

```
Ils sont au nombre de 10 quand même.



## Analyses


On représente le taux de pression graphiquement : Demandes en fonction de Capacité

```{r lycee1}
ggplot(lycee,aes(Demandes,Capacité,col=`Type de diplôme`))+geom_point() +
  ggtitle("Pression")+
  geom_smooth(method="lm")
```

On voit que ça a l'air assez linéaire. Et on voit surtout que certains diplômes
explose les chiffres en terme de demande. 

On voit demander à ggplot de passer en log pour mieux faire la différence.

```{r lycee2}
ggplot(lycee,aes(Demandes,Capacité,col=`Type de diplôme`))+geom_point() +
  ggtitle("Pression")+
  geom_smooth(method="lm")+
  scale_x_continuous(trans = 'log2') +
  scale_y_continuous(trans = 'log2')

```

En fait on voit que c'est vers zéro qu'il y a un problème. Ca peut être du au **log2**.
Mais globalement il n'y a pas d'anomalies à l'oeil.

Et c'est bien logarithmiquement linéaire. Il y a une différence avec plus de capacités
pour les BAC PRO pour les fortes demandes que pour les CAPs où c'est l'inverse.


On regarde le TOP10 des formations en terme de candidats ?

```{r}
kable(lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% arrange(desc(Demandes)) %>%
  slice(1:10))
  
```

On regarde maintenant le taux d'emploi au regard du taux de pression :

```{r lycee3}
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`))+
  geom_point() + geom_smooth(method="lm") + facet_grid(`Type de diplôme` ~ .)
```
Ouf... on s'y attendait pas.

```{r lycee4}
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`))+
  geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .)
```
Apparemment il n'y a pas corrélation claire entre le taux de pression et le taux d'emploi.

On a des points extrêmes, on va ajouter les étiquettes.

```{r lycee5}
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`,label=Diplôme))+
  geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .) + 
  geom_text_repel()
```
Y'a comme un souci...

```{r lycee6}
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`,label=`Code diplôme...12`))+
  geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .) + 
  geom_text_repel()
```

Par exemple :

```{r}
kable(lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme...15"),
                 -`Année première année`) %>% 
  filter(`Code diplôme...12` %in% c(40022402,40023206,40031109,50022362)))
```
Apparemment les charpentiers ne peuvent pas travailler beaucoup.

En fait, on regarde plus systématiquement :

TOP 10 des taux d'emploi :
```{r}
kable(lycee %>% group_by(`Type de diplôme`) %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% slice_max(`Taux d'emploi`,n=10))
```

et l'inverse

```{r}
kable(lycee %>% group_by(`Type de diplôme`) %>% select(-`Année diplôme`,-`Spécialité libellé`,
                 -starts_with("MEFSTAT"),
                 -starts_with("Code Diplôme"),
                 -`Année première année`) %>% slice_min(`Taux d'emploi`,n=10))
```

Est-ce qu'il y a un lien entre l'effectif et le taux d'emploi ?

```{r lycee7}
ggplot(lycee,aes(`Taux de pression`,`Demandes`))+
  geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .) 
```
Il faut qu'on retourne aux **log2**.

```{r lycee8}
ggplot(lycee,aes(`Taux de pression`,`Demandes`))+
  geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .) +
  scale_y_continuous(trans="log2")
```
Apparemment oui mais ce n'est pas linéaire.


Pour faire un graphique avec le taux moyen d'emploi selon la filière ?

```{r lycee10}
graphique <- lycee %>% group_by(Filière) %>% 
  summarise(Moyenne=mean(`Taux d'emploi`))

ggplot(graphique,aes(Filière,Moyenne,fill=Filière)) + geom_bar(color="black",stat="identity")
```
on enlève l'axe des abscisses...


```{r lycee11}
graphique <- lycee %>% group_by(Filière) %>% 
  summarise(Moyenne=mean(`Taux d'emploi`))

ggplot(graphique,aes(Filière,Moyenne,fill=Filière)) + geom_bar(color="black",stat="identity") +
   theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```





## Quiz..


- Faire les TOP10 et l'inverse pour les Taux de pression

- Faire le graphique du taux moyen selon la Filières du Taux de pression


<!--chapter:end:07-emploi.Rmd-->


```{r setupnlp, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(quanteda)
require("quanteda.textmodels")
require("quanteda.textstats")
library(quanteda.textmodels)
library("quanteda.textstats")
library("quanteda.textplots")
library(tidyverse)
require(tm)
library(rainette)
require("udpipe")
require(jsonlite)
library(wordcloud2)
library("textometry")
library(gtsummary)
```

Dans cette partie, on étudie l'utilisation de la réserve parlementaire par les 
députés. 

Ce sont les [données de 2014](https://www.data.gouv.fr/fr/datasets/reserve-parlementaire/)

Les questions sont celles d'une personne naïve et sans a priori : 

- Est-ce que les groupes ont dépensé chacun autant ?

- Est-ce que les groupes ont dépensé chacun autant en moyenne ?

- Est-ce vrai pour les députés en moyenne ?

- Quel est l'enveloppe dépensé au total ?

<!-- - Comment on utilise un tableau de données supplémentaires pour avoir les infos -->
<!-- sur les parlementaires ? -->

- Est-ce possible avec le descriptif d'avoir les mots-clefs pour les sous dépensés ?


```{r}
reserve <- fromJSON("data/reserve/2014_reserve_parlementaire.json")
```



Pourquoi c'est compliqué de faire un gtsummary direct ?

En fait on va se demander si il y a un bénéficiaire qui apparait plusieurs fois.

## Bénéficiaires

```{r}
tb <- table(reserve$Bénéficiaire)
tb1 <- tb[tb>1]
names(tb1)
```



Si oui, est-ce qu'on peut le mettre sous forme de data.frame ? Pourquoi on a 
besoin d'une data.frame pour représenter graphiquement ces informations ?


```{r}
dt <- data.frame(Nom=names(tb1),Nombre=as.numeric(tb1))
dt
```

Une représentation visuelle de la répartition du nombre sur ceux qui ont plus de
2 donations et après sur l'ensemble.



```{r reserve1}
ggplot(dt,aes(Nombre))+geom_histogram()
```

Quels sont les bénéficiaires de plus de 5 donations ? Ce sont des termes génériques
ou des entités ?

```{r}
tbt <- table(reserve$Bénéficiaire)
dt <- data.frame(Nom=names(tbt),Nombre=as.numeric(tbt))
dt[dt$Nombre>5,]
```



```{r reserve2}
tbt <- table(reserve$Bénéficiaire)
dt <- data.frame(Nom=names(tbt),Nombre=as.numeric(tbt))
ggplot(dt,aes(Nombre))+geom_histogram()
```

## Par groupe politique

Si on regarde les dépenses par groupe.


```{r reserve3}
ggplot(dt,aes(Nombre))+geom_histogram()+scale_y_log10()
```


```{r reserve4}
ggplot(reserve,aes(Groupe,Montant))+geom_bar(stat="identity",position="dodge")
```

Mais que ?

```{r}
table(reserve$Groupe)
```


Il faut trouver et corriger.


```{r}

maisque <- reserve %>% filter(Groupe=="")

table(maisque$Nom)

table(maisque$Descriptif)

reserve <- reserve %>% mutate(Groupe=ifelse(Groupe=="","Présidence AN",Groupe))
```


L'erreur corrigée


```{r reserve5}
ggplot(reserve,aes(Groupe,Montant))+geom_bar(stat="identity",position="dodge")
```


Les résultats par groupe avec gtsummary ou summarize.

on en profite pour calculer la somme des donations, la donation moyenne par 
Acteur et le nombre d'acteur par groupe



```{r}
groupe <- reserve %>% group_by(Groupe)

res <- groupe %>% summarize(min=min(Montant),max=max(Montant),
                     Moyenne=mean(Montant),EC=sd(Montant),
                     Somme=sum(Montant),nbActeur=length(unique(ID_Acteur)),
                     Somme_par_acteur=Somme/nbActeur)
res 
```


## Exportation 

Comment l'exporter pour ses collègues ?



```{r}
require(writexl)
write_xlsx(res,"Résultats/Résultats-Deputes-Reserve.xlsx")
```

## Les sommes par acteurs

Les sommes par acteurs selon les groupes

```{r reserve6}
ggplot(res %>% filter(nbActeur != 1),aes(x=Groupe,y=Somme_par_acteur,fill=Groupe))+
  geom_bar(,stat="identity",position="dodge")
```

```{r}

```

## Quoi faire avec le descriptif ?

En utilisant le descriptif :

```{r}
reserve <- reserve %>% mutate(doc_id=paste0("A",1:nrow(reserve)))

reserve_corpus <- corpus(
  reserve,
  text_field = "Descriptif",
  docid_field = "doc_id"
)

mystopwords <- c("loire-atlantique")

tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
  tokens_tolower() %>%
  tokens_remove(stopwords("fr")) %>%
  tokens_wordstem(language="fr") 
  

dtm <- dfm(tok)

res <- rainette(dtm, k = 5)
#rainette_explor(res, dtm, reserve_corpus)

```

```{r}
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
  tokens_tolower() %>%
  tokens_remove(stopwords("fr"))

dtm <- dfm(tok)

top=topfeatures(dtm, 30)
topall=topfeatures(dtm, 300)
top
```

```{r reserve20}
dfreq <- data.frame(word=names(topall),freq=as.numeric(topall))

wordcloud2(dfreq,size=2)
```

<!--chapter:end:08-nlp.Rmd-->


# Enquête Emploi

```{r setupEEC, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("dplyr")

EEC = read.csv2("data/fd_eec19_csv/FD_EEC_2019.csv", header = TRUE, sep = ";", quote = "\"",
                dec = ".", fill = TRUE, comment.char = "")	


```

## Exemple de calcul d'indicateurs

```{r}
summarize(EEC,tauxchom = 100*sum(EXTRIAN*(ACTEU %in% c(2)))/sum(EXTRIAN*(ACTEU %in% c(1,2))))
```


```{r}
summarize(EEC,proportion=sum((ACTEU %in% 2))/sum((ACTEU %in% c(1,2))))*100

summarize(EEC,proportion=sum((SEXE %in% 2))/sum((SEXE %in% c(1,2))))*100

```


```{r}
summarize(EEC,proportion=sum(EXTRIAN*(SEXE %in% 2))/sum(EXTRIAN*(SEXE %in% c(1,2))))*100

summarize(EEC,proportion=sum((SEXE %in% 2 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2) & SEXE %in% 2)))*100
summarize(EEC,proportion=sum((SEXE %in% 1 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2) & SEXE %in% 1)))*100



summarize(EEC,proportion=sum(EXTRIAN*(SEXE %in% 2 & ACTEU %in% 2))/sum(EXTRIAN*(SEXE %in% c(1,2) & ACTEU %in% c(2))))*100

summarize(EEC,tauxCDD50 = 100*sum(EXTRIAN*(AGE3 %in% c(50) & STAT2 %in% c(2) & STATUTR %in% c(4)))/
                    sum(EXTRIAN*(AGE3 %in% c(50) & STAT2 %in% c(2))))

```

                                                   
Calcul de la part de temps partiel parmi les femmes en emploi en moyenne annuelle sur 2019
28,4 % en arrondissant à une décimale

```{r}
summarize(EEC,tauxFTP = 100*sum(EXTRIAN*(SEXE %in% c(2) & ACTEU %in% c(1) & TPPRED %in% c(2)))/
            sum(EXTRIAN*(SEXE %in% c(2) & ACTEU %in% c(1))))                                                 

```
                                               


<!--chapter:end:12-EEC.Rmd-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercices

## Ask A Manager

[Ask A Manager](https://oscarbaruffa.com/messy/)

Which industry pays the most?
How does salary increase given years of experience?
How do salaries compare for the same role in different locations?
How much do salaries differ by gender and years of experience?
How do factors like race and education level correlate with salary?
Is there a “sweet spot” total work experience vs years in the specific field?

## PISA

[PISA 2022](https://www.oecd.org/pisa/data/2022database/)

```{r}
# require(haven)
# data <- read_spss("data/CY08MSP_STU_QQQ.sav")
# extract <- data[,colnames(data)[grep("^(CNT)$|^(WB1[567])|^(ST00\\d)|^(PV\\d+(MATH|READ))",colnames(data))]]
# colnames(extract)
# save(extract,file="data/Pisa.RData")
```

```{r}
load("data/Pisa.RData")
```


<!--chapter:end:exo.Rmd-->

