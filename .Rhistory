wordcloud2(dfreq,scale=2)
wordcloud2(dfreq,size=2)
dfreq <- data.frame(word=names(top),freq=as.numeric(top))
wordcloud2(dfreq,size=2)
dfreq <- data.frame(word=names(topall),freq=as.numeric(topall))
wordcloud2(dfreq,size=2)
library(udpipe)
udmodel <- udpipe_download_model(language = "french")
library(udpipe)
udmodel <- udpipe_download_model(language = "french")
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
tokens_tolower() %>%
tokens_remove(stopwords("fr"))
toktok <- lapply(tok,function(x) udpipe(x,object = udmodel)
)
toktok <- lapply(tok,function(x) ifelse(x!="",udpipe(x,object = udmodel)),"")
toktok <- lapply(tok,function(x) ifelse(x!="",udpipe(x,object = udmodel),""))
toktok
toktok2 <- lapply(toktok,function(x) x[[4]])
toktok2 <- lapply(toktok,function(x) if(length(x)>0,x[[4]],NA))
toktok2 <- lapply(toktok,function(x) ifelse(length(x)>0,x[[4]],NA))
toktok2 <- lapply(toktok,function(x) ifelse(length(x)>0,x[[4]],NA))
toktok2 <- lapply(toktok,function(x) ifelse(length(x)>1,x[[4]],NA))
toktok
toktok <- lapply(tok,function(x) list(ifelse(x!="",udpipe(x,object = udmodel),"")))
toktok
toktok2 <- lapply(toktok,function(x) ifelse(length(x)>1,x[[1]][[4]],NA))
toktok2
toktok2 <- lapply(toktok,function(x) ifelse(length(x[[1]])>0,x[[1]][[4]],NA))
dt[dt$Nombre>5,]
EEC = read.csv2("data/fd_eec19_csv/FD_csv_EEC19.csv", header = TRUE, sep = ";", quote = "\"",
dec = ".", fill = TRUE, comment.char = "")
EEC = read.csv2("data/fd_eec19_csv/FD_EEC_2019.csv", header = TRUE, sep = ";", quote = "\"",
dec = ".", fill = TRUE, comment.char = "")
summarize(EEC,proportion=sum(ACTEU %in% 1)/sum(ACTEU %in% c(2))
summarize(EEC,proportion=sum(ACTEU %in% 1)/sum(ACTEU %in% c(2)))
summarize(EEC,tauxCDD50 = 100*sum(EXTRIAN*(AGE3 %in% c(50) & STAT2 %in% c(2) & STATUTR %in% c(4)))/
sum(EXTRIAN*(AGE3 %in% c(50) & STAT2 %in% c(2))))
summarize(EEC,proportion=sum(EXTRIAN*(ACTEU %in% 1))/sum(EXTRIAN*(ACTEU %in% c(2))))
summarize(EEC,proportion=sum(EXTRIAN*(ACTEU %in% 2))/sum(EXTRIAN*(ACTEU %in% c(1,2))))
summarize(EEC,proportion=sum(EXTRIAN*(ACTEU %in% 2))/sum(EXTRIAN*(ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum((ACTEU %in% 2))/sum((ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum((Sexe %in% 2))/sum((Sexe %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 2))/sum((SEXE %in% c(1,2))))*100
summarize(EEC,proportion=sum(EXTRIAN*(SEXE %in% 2))/sum(EXTRIAN*(SEXE %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 2 & ACTEU %in% 2))/sum((SEXE %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 2 & ACTEU %in% 2))/sum((SEXE %in% c(1,2) & ACTEU %in% c(2))))*100
summarize(EEC,proportion=sum(EXTRIAN*(SEXE %in% 2 & ACTEU %in% 2))/sum(EXTRIAN*(SEXE %in% c(1,2) & ACTEU %in% c(2))))*100
summarize(EEC,proportion=sum((SEXE %in% 2 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 1 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum(EXTRIAN*(SEXE %in% 2 & ACTEU %in% 2))/sum(EXTRIAN*(ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum(EXTRIAN*(SEXE %in% 1 & ACTEU %in% 2))/sum(EXTRIAN*(ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 2 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 1 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2))))*100
summarize(EEC,proportion=sum((SEXE %in% 2 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2) & SEXE %in% 2)))*100
summarize(EEC,proportion=sum((SEXE %in% 1 & ACTEU %in% 2))/sum((ACTEU %in% c(1,2) & SEXE %in% 1)))*100
library(readxl)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(gtsummary)
library(knitr)
library(ggrepel)
lycee <- read_excel("data/fr-en-taux-de-pression-et-demploi.xlsx")
str(lycee)
table(lycee$`Année diplôme`)
lycee$`Année diplôme`
lycee$`Année diplôme`==2019
lycee$`Année diplôme`
table(lycee$`Année diplôme`)
table(lycee$Diplôme)
table(lycee$Diplôme)
table(lycee$`Année diplôme`)
table(lycee$`Spécialité libellé`)
table(lycee$`Année diplôme`)
View(lycee[lycee$`Spécialité libellé`=="POISSONNIER-ECAILLER-TRAITEUR",])
View(lycee %>% filter(`Spécialité libellé`=="POISSONNIER-ECAILLER-TRAITEUR"))
table(lycee$`Spécialité libellé`)
liste=table(lycee$`Spécialité libellé`)
liste <- table(lycee$`Spécialité libellé`)
liste
liste>1
liste[liste>1]
liste <- table(lycee$`Spécialité libellé`)
names(liste)
names(liste)[liste>1]
View(lycee %>% filter(`Spécialité libellé` %in% names(liste)[liste>1]))
19*2
View(lycee %>% filter(`Spécialité libellé` %in% names(liste)[liste>1]) %>%
arrange(`Spécialité libellé`)
)
View(lycee %>% filter(grep("^A",`Spécialité libellé`)))
View(lycee %>% filter(grep("^A",lycee$`Spécialité libellé`)))
?fitler_is
?filter_is
lycee[grep("^A",lycee$`Spécialité libellé`),]
View(lycee[grep("^A",lycee$`Spécialité libellé`),])
lycee %>% select(-`Année diplôme`,-Diplôme,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme"),
-`Année première année`
) %>%
tbl_summary()
plot(rnorm(1000))
density(plot(rnorm(1000)))
density((rnorm(1000)))
plot(density((rnorm(1000))))
plot(density((rnorm(10000000))))
abline(v=1)
abline(v=0)
plot(density(lycee$`Taux d'emploi`))
hist((lycee$`Taux d'emploi`))
plot(density(lycee$`Taux d'emploi`))
abline(v=sd(lycee$`Taux d'emploi`))
plot(density(lycee$`Taux d'emploi`))
abline(v=mean(lycee$`Taux d'emploi`)-sd(lycee$`Taux d'emploi`))
abline(v=mean(lycee$`Taux d'emploi`)+sd(lycee$`Taux d'emploi`))
abline(v=mean(lycee$`Taux d'emploi`),type=3)
abline(v=mean(lycee$`Taux d'emploi`),col="red")
hist(lycee$Capacité)
mean(lycee$Capacité)
plot(density(lycee$Capacité))
str(lycee)
table(lycee$`Code type diplôme`)
lycee$`Code type diplôme` <- factor(lycee$`Code type diplôme`)
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme"),
-`Année première année`) %>%
filter(`Admis apprentissage 2019`==0 | `Admis voie scolaire 2019` == 0)
View(nuls)
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme"),
-`Année première année`) %>%
filter(`Admis apprentissage 2019`==0 & `Admis voie scolaire 2019` == 0)
View(nuls)
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme"),
-`Année première année`) %>%
filter(`Capacité`==0)
kable(nuls)
View(nuls)
nuls <- lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme"),
-`Année première année`) %>%
filter(`Taux d'emploi`==0)
View(nuls)
ggplot(lycee,aes(Demandes,Capacité,col=`Type de diplôme`))+geom_point() +
ggtitle("Pression")+
geom_smooth(method="lm")
ggplot(lycee,aes(Demandes,Capacité,col=`Type de diplôme`))+geom_point() +
ggtitle("Pression")+
geom_smooth(method="lm") +
scale_x_continuous(trans = 'log2') +
scale_y_continuous(trans = 'log2')
View(lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme"),
-`Année première année`) %>% arrange(desc(Demandes)) %>%
slice(1:10))
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`))+
geom_point() + geom_smooth(method="lm") + facet_grid(`Type de diplôme` ~ .)
ggplot(lycee,aes(`Taux de pression`,Demandes))+
geom_point() + geom_smooth(method="lm") + facet_grid(`Type de diplôme` ~ .)
ggplot(lycee,aes(Demandes,`Taux d'emploi`))+
geom_point() + geom_smooth(method="lm") + facet_grid(`Type de diplôme` ~ .)
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`))+
geom_point() + geom_smooth() + facet_grid(`Type de diplôme` ~ .)
ggplot(lycee,aes(Demandes,`Taux d'emploi`))+
geom_point() + geom_smooth() + facet_grid(`Type de diplôme` ~ .) +
scale_x_continuous(trans="log2")
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`,label=Diplôme))+
geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .) +
geom_text_repel()
ggplot(lycee,aes(`Taux de pression`,`Taux d'emploi`,label=`Code diplôme...12`))+
geom_point() + geom_smooth()  + facet_grid(`Type de diplôme` ~ .) +
geom_text_repel()
View(lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme...15"),
-`Année première année`) %>%
filter(`Code diplôme...12` %in% c(40022402,40023206,40031109,50022362)))
View(lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme...15"),
-`Année première année`) %>%
filter(`Code diplôme...12` %in% c(40022402,40023206,40031109,50022362)))
View(lycee %>% select(-`Année diplôme`,-`Spécialité libellé`,
-starts_with("MEFSTAT"),
-starts_with("Code Diplôme...15"),
-`Année première année`) %>%
filter(`Code diplôme...12` %in% c(40023206)))
graphique <- lycee %>% group_by(Filière) %>%
summarise(Moyenne=mean(`Taux d'emploi`))
require(jsonlite)
knitr::opts_chunk$set(echo = TRUE)
require(quanteda)
require("quanteda.textmodels")
require("quanteda.textstats")
library(quanteda.textmodels)
library("quanteda.textstats")
library("quanteda.textplots")
library(tidyverse)
require(tm)
library(rainette)
require("udpipe")
require(jsonlite)
library(wordcloud2)
library("textometry")
library(gtsummary)
reserve <- fromJSON("data/reserve/2014_reserve_parlementaire.json")
View(reserve)
str(reserve)
tb <- table(reserve$Bénéficiaire)
tb
tb[tb>1]
tb <- table(reserve$Bénéficiaire)
tb1 <- tb[tb>1]
names(tb1)
tb
as.numeric(tb)
dt <- data.frame(Nom=names(tb),Nombre=as.numeric(tb))
dt
ggplot(dt,aes(Nombre))+geom_histogram()
dt <- data.frame(Nom=names(tb1),Nombre=as.numeric(tb1))
dt
ggplot(dt,aes(Nombre))+geom_histogram()
ggplot(dt,aes(Nombre))+geom_histogram()+scale_y_log10()
ggplot(reserve,aes(Groupe,Montant))+geom_bar(stat="identity",position="dodge")
table(reserve$Groupe)
maisque <- reserve %>% filter(Groupe=="")
table(maisque$Nom)
Groupe==""
reserve$Groupe==""
ifelse(Groupe=="","Présidence AN",Groupe)
ifelse(reserve$Groupe=="","Présidence AN",Groupe)
ifelse(reserve$Groupe=="","Présidence AN",reserve$Groupe)
reserve <- reserve %>% mutate(Groupe=ifelse(Groupe=="","Présidence AN",Groupe))
table(reserve$Groupe)
ggplot(reserve,aes(Groupe,Montant))+geom_bar(stat="identity",position="dodge")
groupe <- reserve %>% group_by(Groupe)
groupe %>% unique(ID_Acteur)
reserve$ID_Acteur
unique(reserve$ID_Acteur)
length(unique(reserve$ID_Acteur))
res <- groupe %>% summarize(min=min(Montant),max=max(Montant),
Moyenne=mean(Montant),EC=sd(Montant),
Somme=sum(Montant),nbActeur=length(unique(ID_Acteur)),
Somme_par_acteur=Somme/nbActeur)
res
ggplot(reserve,aes(Montant))+geom_histogram()
res
require(writexl)
reserve <- reserve %>% mutate(doc_id=paste0("A",1:nrow(reserve)))
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif",
docid_field = "doc_id"
)
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif",
docid_field = "doc_id"
)
reserve_corpus
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language="fr")
mystopwords <- c("loire-atlantique","c'est")
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language="fr")
dtm <- dfm(tok)
res <- rainette(dtm, k = 5)
rainette_explor(res, dtm, reserve_corpus)
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
%  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
#  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language="fr")
dtm <- dfm(tok)
res <- rainette(dtm, k = 5)
rainette_explor(res, dtm, reserve_corpus)
str(reserve)
rr <- read_json("data/reserve/AMO10_deputes_actifs_mandats_actifs_organes_XIV.json")
rr
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>%
tokens_tolower() %>%
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language = "fr")
dtm <- dfm(tok)
top=topfeatures(dtm, 30)
topall=topfeatures(dtm, 300)
top
install.packages("lcmm")
options(digits=2)
require(likert)
install.packages("pisatitems")
install.packages("likert")
require(likert)
data(pisaitems)
items24 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST24Q']
head(items24); ncol(items24)
names(items24) <- c(
ST24Q01="I read only if I have to.",
ST24Q02="Reading is one of my favorite hobbies.",
ST24Q03="I like talking about books with other people.",
ST24Q04="I find it hard to finish books.",
ST24Q05="I feel happy if I receive a book as a present.",
ST24Q06="For me, reading is a waste of time.",
ST24Q07="I enjoy going to a bookstore or a library.",
ST24Q08="I read only to get information that I need.",
ST24Q09="I cannot sit still and read for more than a few minutes.",
ST24Q10="I like to express my opinions about books I have read.",
ST24Q11="I like to exchange books with my friends.")
str(items24)
l24 <- likert(items24)
l24 #print(l24)
summary(l24)
l24
items24
summary(l24)
summary(l24, center=1.5)
summary(l24, center=2)
# xtable
xtable(l24)
# Plots
plot(l24)
plot(l24, ordered=FALSE, group.order=names(items24)) #Specify the exact order of the y-axis
plot(l24, ordered=FALSE, group.order=names(items24)) #Specify the exact order of the y-axis
# Plots
plot(l24)
plot(l24, centered=FALSE, wrap=30)
plot(l24, center=1.5, wrap=30)
plot(l24, center=2, wrap=30)
plot(l24, center=2, include.center=FALSE, wrap=30)
plot(l24, center=2, include.center=FALSE, wrap=20)
plot(l24, plot.percents=TRUE, plot.percent.low=FALSE, plot.percent.high=FALSE)
plot(l24, plot.percents=TRUE, plot.percent.low=FALSE, plot.percent.high=FALSE)
plot(l24, center=2, plot.percents=TRUE, plot.percent.low=FALSE, plot.percent.high=FALSE)
plot(l24, colors=c('orange','darkorange','darkblue','blue'))
#Include histogram with response counts
plot(l24, include.histogram=TRUE)
#Include histogram with response counts
plot(l24, include.histogram=TRUE)
plot(l24, include.histogram=TRUE)
plot(l24, type='density', facet=FALSE)
plot(l24, type='density', facet=FALSE) + guides(color = guide_legend(title="New Legend Title"),
fill = guide_legend(title="New Legend Title"))
# Heat map
plot(l24, type='heat', wrap=30, text.size=4, digits = 0)
plot(l24, type='heat', wrap=30, text.size=4, digits = 3)
# Reverse the levels
items24.reverse <- reverse.levels(items24)
l24.reverse <- likert(items24.reverse)
print(l24.reverse)
plot(l24.reverse)
##### Group by Country
l24g <- likert(items24, grouping=pisaitems$CNT)
print(l24g)
summary(l24g)
summary(l24g, center=1.5)
summary(l24g, center=2)
# Plots
plot(l24g)
plot(l24g, centered=FALSE)
# Plots
plot(l24g)
#Include histogram with response counts
plot(l24g, include.histogram=TRUE)
# Alternate panel arrangements.
plot(l24g, panel.arrange='h', wrap=20)
plot(l24g, panel.arrange=NULL, wrap=40)
##### Item 29: How often do you read these materials because you want to?
title <- "How often do you read these materials because you want to?"
items29 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST25Q']
head(items29); ncol(items29)
names(items29) = c("Magazines", "Comic books", "Fiction", "Non-fiction books", "Newspapers")
l29 <- likert(items29)
print(l29)
summary(l29)
# xtable
xtable(l29)
# Plots
plot(l29) + ggtitle(title)
plot(l29, centered=TRUE) + ggtitle(title)
plot(l29, centered=TRUE, include.center=FALSE) + ggtitle(title)
plot(l29, centered=TRUE, center=2) + ggtitle(title)
plot(l29, centered=TRUE, center=2.5) + ggtitle(title)
plot(l29, centered=TRUE, center=2.5) + ggtitle(title)
knitr::opts_chunk$set(echo = TRUE)
require(quanteda)
require("quanteda.textmodels")
require("quanteda.textstats")
library(quanteda.textmodels)
library("quanteda.textstats")
library("quanteda.textplots")
library(tidyverse)
require(tm)
library(rainette)
require("udpipe")
require(jsonlite)
library(wordcloud2)
library("textometry")
library(gtsummary)
reserve <- fromJSON("data/reserve/2014_reserve_parlementaire.json")
str(reserve)
tb <- table(reserve$Bénéficiaire)
tb1 <- tb[tb>1]
names(tb1)
dt <- data.frame(Nom=names(tb),Nombre=as.numeric(tb))
dt
ggplot(dt,aes(Nombre))+geom_histogram()
tbt <- table(reserve$Bénéficiaire)
dt <- data.frame(Nom=names(tbt),Nombre=as.numeric(tbt))
dt[dt$Nombre>5,]
tbt <- table(reserve$Bénéficiaire)
dt <- data.frame(Nom=names(tbt),Nombre=as.numeric(tbt))
ggplot(dt,aes(Nombre))+geom_histogram()
ggplot(dt,aes(Nombre))+geom_histogram()+scale_y_log10()
ggplot(reserve,aes(Groupe,Montant))+geom_bar(stat="identity",position="dodge")
table(reserve$Groupe)
maisque <- reserve %>% filter(Groupe=="")
table(maisque$Nom)
table(maisque$Descriptif)
reserve <- reserve %>% mutate(Groupe=ifelse(Groupe=="","Présidence AN",Groupe))
ggplot(reserve,aes(Groupe,Montant))+geom_bar(stat="identity",position="dodge")
groupe <- reserve %>% group_by(Groupe)
res <- groupe %>% summarize(min=min(Montant),max=max(Montant),
Moyenne=mean(Montant),EC=sd(Montant),
Somme=sum(Montant),nbActeur=length(unique(ID_Acteur)),
Somme_par_acteur=Somme/nbActeur)
res
require(writexl)
write_xlsx(res,"Résultats/Résultats-Deputes-Reserve.xlsx")
ggplot(res %>% filter(nbActeur != 1),aes(x=Groupe,y=Somme_par_acteur,fill=Groupe))+
geom_bar(,stat="identity",position="dodge")
reserve <- reserve %>% mutate(doc_id=paste0("A",1:nrow(reserve)))
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif"
)
?corpus
reserve
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif",
docid_field = "doc_id"
)
reserve <- reserve %>% mutate(doc_id=paste0("A",1:nrow(reserve)))
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif",
docid_field = "doc_id"
)
mystopwords <- c("loire-atlantique","c'est")
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
#  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language="fr")
dtm <- dfm(tok)
res <- rainette(dtm, k = 5,min_segment_size = 5)
rainette_explor(res, dtm, reserve_corpus)
res <- rainette(dtm, k = 5,min_segment_size = 5)
reserve_corpus
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif",
docid_field = "doc_id"
)
mystopwords <- c("loire-atlantique","c'est")
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
#  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language="fr")
dtm <- dfm(tok)
res <- rainette(dtm, k = 5,min_segment_size = 5)
dtm <- dfm(tok,T)
dtm <- dfm(tok,verbose=T)
res <- rainette(dtm, k = 5,min_segment_size = 5)
reserve <- reserve %>% mutate(doc_id=paste0("A",1:nrow(reserve)))
reserve_corpus <- corpus(
reserve,
text_field = "Descriptif",
docid_field = "doc_id"
)
mystopwords <- c("loire-atlantique","c'est")
tok <- tokens(reserve_corpus, remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
#  tokens_remove(pattern = mystopwords,valuetype = 'fixed') %>
tokens_remove(stopwords("fr")) %>%
tokens_wordstem(language="fr")
dtm <- dfm(tok)
dtm
res <- rainette(dtm, k = 5,min_segment_size = 5)
dtm
res <- rainette(dtm, k = 5)
rainette_explor(res, dtm, reserve_corpus)
